{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from utils.utils import generate_results_csv\n",
        "from utils.utils import create_directory\n",
        "from utils.utils import read_dataset\n",
        "from utils.utils import transform_mts_to_ucr_format\n",
        "from utils.utils import visualize_filter\n",
        "from utils.utils import viz_for_survey_paper\n",
        "from utils.utils import viz_cam\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import sklearn\n",
        "import utils\n",
        "from utils.constants import CLASSIFIERS\n",
        "from utils.constants import ARCHIVE_NAMES\n",
        "from utils.constants import ITERATIONS\n",
        "from utils.utils import read_all_datasets\n",
        "\n",
        "\n",
        "def fit_classifier():\n",
        "    x_train = datasets_dict[dataset_name][0]\n",
        "    y_train = datasets_dict[dataset_name][1]\n",
        "    x_test = datasets_dict[dataset_name][2]\n",
        "    y_test = datasets_dict[dataset_name][3]\n",
        "\n",
        "    # x_train\uacfc x_test\ub97c numpy \ubc30\uc5f4\ub85c \ubcc0\ud658\n",
        "    x_train = np.array(x_train)\n",
        "    x_test = np.array(x_test)\n",
        "\n",
        "    # y_train\uacfc y_test\ub97c numpy \ubc30\uc5f4\ub85c \ubcc0\ud658\ud558\uace0, float \ud0c0\uc785\uc73c\ub85c \ubcc0\uacbd\n",
        "    y_train = np.array(y_train).astype(float)\n",
        "    y_test = np.array(y_test).astype(float)\n",
        "\n",
        "    nb_classes = len(np.unique(np.concatenate((y_train, y_test), axis=0)))\n",
        "\n",
        "    # transform the labels from integers to one hot vectors\n",
        "    enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
        "    enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))\n",
        "    y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
        "    y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
        "\n",
        "    # save original y because later we will use binary\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "    if len(x_train.shape) == 2:  # if univariate\n",
        "        # add a dimension to make it multivariate with one dimension\n",
        "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "    input_shape = x_train.shape[1:]\n",
        "    classifier = create_classifier(classifier_name, input_shape, nb_classes, output_directory)\n",
        "\n",
        "    classifier.fit(x_train, y_train, x_test, y_test, y_true)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_classifier(classifier_name, input_shape, nb_classes, output_directory, verbose=True):\n",
        "    if classifier_name == 'fcn':\n",
        "        from classifiers import fcn\n",
        "        return fcn.Classifier_FCN(output_directory, input_shape, nb_classes, verbose)\n",
        "    if classifier_name == 'mlp':\n",
        "        from classifiers import mlp\n",
        "        return mlp.Classifier_MLP(output_directory, input_shape, nb_classes, verbose)\n",
        "    if classifier_name == 'resnet':\n",
        "        from classifiers import resnet\n",
        "        return resnet.Classifier_RESNET(output_directory, input_shape, nb_classes, verbose)\n",
        "    if classifier_name == 'mcnn':\n",
        "        from classifiers import mcnn\n",
        "        return mcnn.Classifier_MCNN(output_directory, verbose)\n",
        "    if classifier_name == 'tlenet':\n",
        "        from classifiers import tlenet\n",
        "        return tlenet.Classifier_TLENET(output_directory, verbose)\n",
        "    if classifier_name == 'twiesn':\n",
        "        from classifiers import twiesn\n",
        "        return twiesn.Classifier_TWIESN(output_directory, verbose)\n",
        "    if classifier_name == 'encoder':\n",
        "        from classifiers import encoder\n",
        "        return encoder.Classifier_ENCODER(output_directory, input_shape, nb_classes, verbose)\n",
        "    if classifier_name == 'mcdcnn':\n",
        "        from classifiers import mcdcnn\n",
        "        return mcdcnn.Classifier_MCDCNN(output_directory, input_shape, nb_classes, verbose)\n",
        "    if classifier_name == 'cnn':  # Time-CNN\n",
        "        from classifiers import cnn\n",
        "        return cnn.Classifier_CNN(output_directory, input_shape, nb_classes, verbose)\n",
        "    if classifier_name == 'inception':\n",
        "        from classifiers import inception\n",
        "        return inception.Classifier_INCEPTION(output_directory, input_shape, nb_classes, verbose)\n",
        "\n",
        "\n",
        "# main\n",
        "\n",
        "# change this directory for your machine\n",
        "root_dir = '/Users/yewon/PycharmProjects/pytorch4'\n",
        "archive_name = 'mts_Archive'\n",
        "dataset_name = 'WalkvsRun_TRAIN'\n",
        "\n",
        "import sys\n",
        "\n",
        "# \uba85\ub839\uc904 \uc778\uc218\uac00 \uc81c\ub300\ub85c \uc804\ub2ec\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\n",
        "print(\"sys.argv:\", sys.argv)\n",
        "if len(sys.argv) < 2:\n",
        "    print(\"Error: Not enough command line arguments provided.\")\n",
        "    print(\"Usage: python main.py <command>\")\n",
        "    print(\"Available commands: run_all, transform_mts_to_ucr_format, visualize_filter, viz_for_survey_paper, viz_cam, generate_results_csv\")\n",
        "    sys.exit(1)\n",
        "\n",
        "if sys.argv[1] == 'run_all':\n",
        "    for classifier_name in CLASSIFIERS:\n",
        "        print('classifier_name', classifier_name)\n",
        "\n",
        "        for archive_name in ARCHIVE_NAMES:\n",
        "            print('\\tarchive_name', archive_name)\n",
        "            archive_name = archive_name.lower()\n",
        "            if archive_name == 'mtsarchive':\n",
        "                archive_name = 'mts_archive'\n",
        "            datasets_dict = read_all_datasets(root_dir, archive_name)\n",
        "\n",
        "            for iter in range(ITERATIONS):\n",
        "                print('\\t\\titer', iter)\n",
        "\n",
        "                trr = ''\n",
        "                if iter != 0:\n",
        "                    trr = '_itr_' + str(iter)\n",
        "\n",
        "                tmp_output_directory = root_dir + '/results/' + classifier_name + '/' + archive_name + trr + '/'\n",
        "                print(f\"root_dir: {root_dir}\")\n",
        "                print(f\"classifier_name: {classifier_name}\")\n",
        "                print(f\"archive_name: {archive_name}\")\n",
        "                print(f\"trr: {trr}\")\n",
        "                print(f\"tmp_output_directory: {tmp_output_directory}\")\n",
        "\n",
        "                # archive_name\uc744 \uc18c\ubb38\uc790\ub85c \ubcc0\ud658\ud558\uc5ec \uc0ac\uc6a9\n",
        "                archive_name = archive_name.lower()\n",
        "\n",
        "                # \ub514\ubc84\uae45\uc744 \uc704\ud55c \ucd9c\ub825 \ucd94\uac00\n",
        "                print(f\"archive_name: {archive_name}\")\n",
        "                print(f\"dataset_names_for_archive keys: {utils.constants.dataset_names_for_archive.keys()}\")\n",
        "\n",
        "                # for\ubb38\uc5d0\uc11c dataset_name\uc744 \ucc3e\uc744 \ub54c \uc815\ud655\ud788 \ud0a4\uac00 \uc788\ub294\uc9c0 \ud655\uc778 \ud6c4 \uc0ac\uc6a9\n",
        "                if archive_name in utils.constants.dataset_names_for_archive:\n",
        "                    for dataset_name in utils.constants.dataset_names_for_archive[archive_name]:\n",
        "                        print('\\t\\t\\tdataset_name: ', dataset_name)\n",
        "\n",
        "                        output_directory = tmp_output_directory + dataset_name + '/'\n",
        "\n",
        "                        create_directory(output_directory)\n",
        "\n",
        "                        fit_classifier()\n",
        "\n",
        "                        print('\\t\\t\\t\\tDONE')\n",
        "\n",
        "                        # the creation of this directory means\n",
        "                        create_directory(output_directory + '/DONE')\n",
        "                else:\n",
        "                    print(f\"Error: {archive_name} \ud0a4\uac00 dataset_names_for_archive\uc5d0 \uc874\uc7ac\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n",
        "\n",
        "\n",
        "elif sys.argv[1] == 'transform_mts_to_ucr_format':\n",
        "    transform_mts_to_ucr_format()\n",
        "\n",
        "elif sys.argv[1] == 'visualize_filter':\n",
        "    visualize_filter(root_dir)\n",
        "\n",
        "elif sys.argv[1] == 'viz_for_survey_paper':\n",
        "    viz_for_survey_paper(root_dir)\n",
        "\n",
        "elif sys.argv[1] == 'viz_cam':\n",
        "    viz_cam(root_dir)\n",
        "\n",
        "elif sys.argv[1] == 'generate_results_csv':\n",
        "    res = generate_results_csv('results.csv', root_dir)\n",
        "    print(res.to_string())\n",
        "\n",
        "else:\n",
        "    if len(sys.argv) < 5:\n",
        "        print(\"Error: Not enough arguments for running an experiment.\")\n",
        "        print(\"Usage: python main.py <archive_name> <dataset_name> <classifier_name> <iteration>\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # \uc778\uc218\uc5d0 \ub530\ub978 \uc2e4\ud5d8 \uc2e4\ud589 \ucf54\ub4dc\n",
        "    archive_name = sys.argv[1]\n",
        "    dataset_name = sys.argv[2]\n",
        "    classifier_name = sys.argv[3]\n",
        "    itr = sys.argv[4]\n",
        "\n",
        "    if itr == '_itr_0':\n",
        "        itr = ''\n",
        "\n",
        "    output_directory = root_dir + '/results/' + classifier_name + '/' + archive_name + itr + '/' + dataset_name + '/'\n",
        "\n",
        "    test_dir_df_metrics = output_directory + 'df_metrics.csv'\n",
        "\n",
        "    print('Method: ', archive_name, dataset_name, classifier_name, itr)\n",
        "\n",
        "    if os.path.exists(test_dir_df_metrics):\n",
        "        print('Already done')\n",
        "    else:\n",
        "        create_directory(output_directory)\n",
        "        datasets_dict = read_dataset(root_dir, archive_name, dataset_name)\n",
        "\n",
        "        fit_classifier()\n",
        "\n",
        "        print('DONE')\n",
        "\n",
        "        # the creation of this directory means\n",
        "        create_directory(output_directory + '/DONE')\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}